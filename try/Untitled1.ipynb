{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Flatten, Input, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "\n",
    "import h5py  # compress and save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with h5py.File('features_train.h5', 'r') as f:\n",
    "    features = np.array(f['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with h5py.File('features_test.h5', 'r') as f:\n",
    "    feature_test = np.array(f['features_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroMean(dataMat):        \n",
    "    meanVal=np.mean(dataMat,axis=0)     #get mean by columns\n",
    "    newData=dataMat-meanVal  \n",
    "    return newData,meanVal\n",
    "\n",
    "\n",
    "def percentage2n(eigVals,percentage):  \n",
    "    sortArray=np.sort(eigVals)          #ascend order \n",
    "    sortArray=sortArray[-1::-1]           \n",
    "    arraySum=sum(sortArray)  \n",
    "    tmpSum=0  \n",
    "    num=0  \n",
    "    for i in sortArray:  \n",
    "        tmpSum+=i  \n",
    "        num+=1  \n",
    "        if tmpSum>=arraySum*percentage:  \n",
    "            return num  \n",
    "\n",
    "\n",
    "def pca(dataMat,percentage=0.99):  \n",
    "    newData,meanVal=zeroMean(dataMat)  \n",
    "    covMat=np.cov(newData,rowvar=0)      #covariance  \n",
    "    eigVals,eigVects=np.linalg.eig(np.mat(covMat))      \n",
    "    n=percentage2n(eigVals,percentage)                 #need n dimensionol data to get the convariance percentage\n",
    "    #eigValIndice=np.argsort(eigVals)            #ascend order \n",
    "    #n_eigValIndice=eigValIndice[-1:-(n+1):-1]   \n",
    "    #n_eigVect=eigVects[:,n_eigValIndice]        \n",
    "    #lowDDataMat=newData*n_eigVect               #lower dimensional data  \n",
    "    #reconMat=(lowDDataMat*n_eigVect.T)+meanVal  #reconstruct data  \n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = pca(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
